{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15271a8",
   "metadata": {},
   "source": [
    "# 음악정보검색 오디오 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb19300e",
   "metadata": {},
   "source": [
    "내용 기반 음악정보검색 분야 연구를 위해서는 많은 양의 오디오 데이터/메타데이터가 필요하다.\n",
    "\n",
    "연구의 [유형](https://jo-cho.github.io/MIRBlog/posts/1.%20Introduction/1.1.Introduction.html)에 따라 유용한 데이터 세트를 소개하고, 다운로드 받을 수 있는 링크를 걸어두었다.\n",
    "\n",
    "소개한 데이터 세트는 많은 연구들에서 주로 사용되는 데이터 세트로, 데이터의 연도, 음악의 종류, 데이터의 파일 유형, 연구 목적 등을 고려해 필요한 것을 골라 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b528f2c",
   "metadata": {},
   "source": [
    "## 악기 인지 (instrument recognition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e7031e",
   "metadata": {},
   "source": [
    "- [Drumpt](https://github.com/cwu307/DrumPtDataset) (2000개)\n",
    "    - 드럼 연주 기법(4가지) 감지 관련 연구를 위해 생성된 데이터 세트\n",
    "    \n",
    "    \n",
    "- [Good-sounds.org](https://www.upf.edu/web/mtg/good-sounds) (8750개 음)\n",
    "    - 12개 악기의 단일 음과 음계에 대한 실험을 위한 모노(mono)음 녹음이 포함된 데이터 세트\n",
    "    \n",
    "    \n",
    "- [IDMT-SMT](https://www.idmt.fraunhofer.de/en/publications/datasets.html) (이펙트:55044개, 베이스:4300개, 드럼:518개, 기타:5100개)\n",
    "    - 악기 감지, 핑거링, 연주 분석과 같은 다양한 연구 영역을 위한 오디오 데이터 세트\n",
    "    \n",
    "    \n",
    "- [IRMAS](https://www.upf.edu/web/mtg/irmas) (2874개 오디오 발췌)\n",
    "    - 주요 악기의 주석이 있는 음악 오디오 발췌 부분이 포함된 데이터 세트\n",
    "    \n",
    "    \n",
    "- [Medley-solos-DB](https://zenodo.org/record/2582103#.Y_b-wHZByUk) (21572개 오디오 발췌)\n",
    "    - 단일 녹음의 자동 악기 인식을 위한 교차 수집(cross-collection) 데이터 세트\n",
    "    \n",
    "    \n",
    "- [NSynth](https://magenta.tensorflow.org/datasets/nsynth) (305979개 단일 음)\n",
    "    - 주석이 달린 음의 대규모 데이터 세트\n",
    "\n",
    "\n",
    "- [RWC - Musical Instrument](https://staff.aist.go.jp/m.goto/RWC-MDB/) (150개 연주 - 악기당 3개) - 2001년\n",
    "    - RWC 데이터 세트는 50개의 악기를 포함하며 선행연구에서 가장 많이 사용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdc3841",
   "metadata": {},
   "source": [
    "## 소스 분리 (source separation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b705fc02",
   "metadata": {},
   "source": [
    "- [CCMixer](https://members.loria.fr/ALiutkus/kam/) (50개 믹스)\n",
    "    - 보컬과 백그라운드 트랙으로 구성된 데이터 세트\n",
    "    \n",
    "    \n",
    "- [DREANSS](https://www.upf.edu/web/mtg/dreanss) (22개 멀티트랙 오디오와 주석)\n",
    "    - 드럼이 포함된 멀티트랙 오디오 음악 믹스에 대한 소스 분리 연구를 위한 데이터 세트\n",
    "\n",
    "\n",
    "- [IDMT-MT](https://www.jyu.fi/hytk/fi/laitokset/mutku/en/research/projects2/past-projects/coe/materials/Multitrack/Multitrack) (12개 노래)\n",
    "    - 베이스, 기타, 드럼 세트로 구성된 스윙, 블루스, 훵크 스타일 멀티트랙 데이터 세트\n",
    "\n",
    "\n",
    "- [JGDB](https://ccrma.stanford.edu/~jga/ismir2010/ismir2010.html) (128개 악기 혹은 20개 악기 믹스)\n",
    "    - 무작위 생성된 미디 파일로 만든 멀티트랙 데이터\n",
    "    \n",
    "    \n",
    "- [MedleyDB](https://medleydb.weebly.com/) (122개 노래)\n",
    "    - 소스 분리 및 자동 믹싱 등을 위해 멜로디 주석과 악기 활성화가 포함된 멀티트랙 데이터 세트\n",
    "\n",
    "\n",
    "- [MIR-1K](https://sites.google.com/site/unvoicedsoundseparation/mir-1k) (1000개 오디오 발췌)\n",
    "    - 주석과 함께 음악 반주와 노래 음성이 왼쪽 채널과 오른쪽 채널에 각각 녹음된 데이터 세트 \n",
    "\n",
    "\n",
    "- [SMD](https://resources.mpi-inf.mpg.de/SMD/SMD_MIDI-Audio-Piano-Music.html) (50개 녹음)\n",
    "    - 다양한 피아노 곡에 대해 완벽하게 동기화된 MIDI 파일과 오디오 녹음의 데이터 세트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f261907",
   "metadata": {},
   "source": [
    "## 장르 분류 (genre classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9680b4",
   "metadata": {},
   "source": [
    "- [AcousticBrainz-Genre](https://mtg.github.io/acousticbrainz-genre-dataset/) (2백만곡, 31장르, 745하위장르)\n",
    "    - 다양한 메타데이터 소스의 계층적 다중-라벨 장르 주석의 데이터 세트로 오디오 데이터는 미포함\n",
    "   \n",
    "   \n",
    "- [Coidach](https://jmir.sourceforge.net/Codaich.html) (26420곡, 55장르) - *2006년*\n",
    "    - 55개 장르로 이루어진 MP3 오디오 데이터 세트\n",
    "    \n",
    "    \n",
    "- [ExtendedBallroom](http://anasynth.ircam.fr/home/media/ExtendedBallroom/) (4000곡, 9장르) - *2016년*\n",
    "    - 4000곡의 30초 오디오로 장르와 노래 메타데이터를 포함한 데이터 세트로 오디오 데이터는 미포함\n",
    "\n",
    "\n",
    "- [FMA](https://github.com/mdeff/fma) (106574곡, 최대 161장르) - *2017년*\n",
    "    - 최근 가장 많이 쓰이는 데이터세트 중 하나로 full(106574곡 전체), large(106574곡 30초), medium(25000곡 30초), small(8000곡 30초)로 구분되며, 각각 161개, 16개, 8개 장르로 구분되는 오디오 데이터와 유저레벨, 트랙 별 메타데이터, 태그 등이 포함된 데이터 세트\n",
    "    \n",
    "    \n",
    "- [GTZAN](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification) (1000곡, 10장르) - *2002년*\n",
    "    - 가장 많이 쓰이는 벤치마크 데이터로 10개 장르마다 100곡씩 총 1000곡으로 구성된 오디오 데이터 세트 (단, 저작권, 아티스트 불균형, 겹치는 곡 등의 문제로 최근 잘 쓰이지 않는 추세)\n",
    "\n",
    "\n",
    "- [Homburg](https://www-ai.cs.tu-dortmund.de/audio.html) (1886곡, 9장르) - *2005년*\n",
    "    - 9개 장르로 나누어진 MP3 오디오 데이터 세트\n",
    "    \n",
    "    \n",
    "- [MSD(million song dataset)](http://millionsongdataset.com/) (1백만곡) - *2011년*\n",
    "    - 100만 곡의 피쳐 분석과 메타데이터로 이루어진 데이터 세트로 오디오 데이터는 미포함\n",
    "    \n",
    "    \n",
    "- [RWC - Music Database: Music Genre](https://staff.aist.go.jp/m.goto/RWC-MDB/rwc-mdb-g.html) (100곡, 34장르) - *2001년*\n",
    "    - 33개 장르별 3곡, 아카펠라 1곡 총 100곡으로 구성된 데이터 세트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6470289",
   "metadata": {},
   "source": [
    "## 무드 추정 (Mood Estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262d0dbc",
   "metadata": {},
   "source": [
    "- [Amg1608](https://amg1608.blogspot.com/) (1608곡)\n",
    "    - 30초 오디오 클립과 VA(valence-arousal) 주석이 포함된 음악 감정 인식 데이터 세트\n",
    "    \n",
    "    \n",
    "- [DEAM](https://cvml.unige.ch/databases/DEAM/) (1802곡)\n",
    "    - VA 주석이 포함된 오디오 데이터 세트\n",
    "\n",
    "\n",
    "- [EmoMusic](https://cvml.unige.ch/databases/emoMusic/) (1000곡)\n",
    "    - FMA로부터 선택한 1000곡의 45초 발췌와 함께 연속적 주석이 포함된 데이터 세트\n",
    "    \n",
    "    \n",
    "- [Emotify](http://www2.projects.science.uu.nl/memotion/emotifydata/) (400곡)\n",
    "    - 1분짜리 400곡과 함께 GEMS(Geneva Emotional Music Scales) 스케일(9종류의 무드 중 참여자가 정한 무드 주석)과 참여자 정보를 포함한 데이터 세트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b236baf1",
   "metadata": {},
   "source": [
    "## 허밍/태핑 기반 검색 (Query-by-Humming,-Tapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e61757",
   "metadata": {},
   "source": [
    "- [MTG-QBH](https://www.upf.edu/web/mtg/mtg-qbh) (118개 오디오)\n",
    "    - 17명(여자9, 남자8)이 부른 멜로디의 오디오 데이터 세트\n",
    "        \n",
    "        \n",
    "- [QBT-Extended](https://ccrma.stanford.edu/groups/qbtextended/dataset.html) (3365 쿼리, 51곡)\n",
    "    - 기준 노래의 미디 데이터와 실험자의 태핑(tapping) 온셋 데이터 세트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675627c6",
   "metadata": {},
   "source": [
    "## 온셋 감지/ 음악 주석 (Onset Detection, Music Annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4db31c4",
   "metadata": {},
   "source": [
    "- [CAL500](http://calab1.ucsd.edu/~datasets/) (502곡) - *2010년*\n",
    "    - ground truth 태그를 포함한 데이터 세트\n",
    "\n",
    "\n",
    "- [CMMSD](https://sourceforge.net/projects/segmentationgt/) (36개)\n",
    "    - 분할 ground truth 데이터로 텍스트 파일 등의 데이터 세트\n",
    "\n",
    "\n",
    "- [MARG-AMT](http://marg.snu.ac.kr/automatic-music-transcription/) (30개 멜로디)\n",
    "    - 온셋 감지, 피치 추정 등을 위한 음-수준(note-level)의 노래하는 음성 데이터 세트\n",
    "\n",
    "\n",
    "- [Modal](https://github.com/johnglover/modal) (71개 스니펫)\n",
    "    - 온셋 감지 평가 목적으로 직접 주석을 단 온셋 위치가 있는 음악 샘플 데이터베이스\n",
    "    \n",
    "    \n",
    "- [MuisClef2012](http://www.cp.jku.at/datasets/musiclef/index.html) (1335곡) - *2012년*\n",
    "    - 218명의 아티스트가 작곡한 1355곡의 대중 음악에 대한 태그를 포함한 메타데이터\n",
    "\n",
    "\n",
    "- [MusicNet](https://zenodo.org/record/5120004#.Y_c-QnZByUl) (330개 녹음)\n",
    "    - 각 음의 정확한 시간, 연주하는 악기, 음표의 위치를 나타내는 주석 라벨이 폼함된 330개의 클래식 음악 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e80ac0",
   "metadata": {},
   "source": [
    "# 참고자료\n",
    "\n",
    "- Murthy, YV Srinivasa, and Shashidhar G. Koolagudi. \"Content-based music information retrieval (cb-mir) and its applications toward the music industry: A review.\" ACM Computing Surveys (CSUR) 51.3 (2018): 1-46.\n",
    "- https://www.ismir.net/resources/datasets/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
